from dotenv import load_dotenv   # lit les variables depuis un fichier .env
import os                         # pour accéder aux variables d'environnement
from PIL import Image, ImageDraw  # pour ouvrir et dessiner sur les images
import sys                        # pour récupérer les arguments passés au script
from matplotlib import pyplot as plt  # pour afficher les images
from azure.core.exceptions import HttpResponseError  # gérer les erreurs Azure
import requests                   # pour télécharger des fichiers depuis internet

# import namespaces
from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.ai.vision.imageanalysis.models import VisualFeatures
from azure.core.credentials import AzureKeyCredential

# ================================
# Fonction principale du script
# ================================
def main():

    # Efface la console (Windows ou Linux/Mac)
    os.system('cls' if os.name=='nt' else 'clear')

    try:
        # Charger les variables d'environnement depuis le fichier .env
        load_dotenv()
        ai_endpoint = os.getenv('AI_SERVICE_ENDPOINT')  # endpoint Azure
        ai_key = os.getenv('AI_SERVICE_KEY')            # clé API Azure

        # Choisir l'image à analyser (par défaut street.jpg)
        image_file = 'images/street.jpg'
        if len(sys.argv) > 1:
            image_file = sys.argv[1]

        # Créer le client Azure AI Vision pour l'analyse d'images
        cv_client = ImageAnalysisClient(
            endpoint=ai_endpoint,
            credential=AzureKeyCredential(ai_key))

        # Ouvrir et lire l'image
        with open(image_file, "rb") as f:
            image_data = f.read()
        print(f'\nAnalyzing {image_file}\n')

        # Analyser l'image avec les fonctionnalités demandées
        result = cv_client.analyze(
            image_data=image_data,
            visual_features=[
                VisualFeatures.CAPTION,
                VisualFeatures.DENSE_CAPTIONS,
                VisualFeatures.TAGS,
                VisualFeatures.OBJECTS,
                VisualFeatures.PEOPLE],
        )

        # Afficher les captions (description automatique)
        if result.caption is not None:
            print("\nCaption:")
            print(" Caption: '{}' (confidence: {:.2f}%)".format(result.caption.text, result.caption.confidence * 100))
            
        if result.dense_captions is not None:
            print("\nDense Captions:")
            for caption in result.dense_captions.list:
                print(" Caption: '{}' (confidence: {:.2f}%)".format(caption.text, caption.confidence * 100))

        # Afficher les tags (mots-clés suggérés)
        if result.tags is not None:
            print("\nTags:")
            for tag in result.tags.list:
                print(" Tag: '{}' (confidence: {:.2f}%)".format(tag.name, tag.confidence * 100))

        # Afficher et annoter les objets détectés
        if result.objects is not None:
            print("\nObjects in image:")
            for detected_object in result.objects.list:
                print(" {} (confidence: {:.2f}%)".format(detected_object.tags[0].name, detected_object.tags[0].confidence * 100))
            show_objects(image_file, result.objects.list)  # appel de la fonction pour dessiner

        # Afficher et annoter les personnes détectées
        if result.people is not None:
            print("\nPeople in image:")
            for detected_person in result.people.list:
                if detected_person.confidence > 0.2:
                    print(" {} (confidence: {:.2f}%)".format(detected_person.bounding_box, detected_person.confidence * 100))
            show_people(image_file, result.people.list)  # appel de la fonction pour dessiner

    except Exception as ex:
        print(ex)  # afficher les erreurs éventuelles


# ================================
# Fonction pour annoter les objets sur l'image
# ================================
def show_objects(image_filename, detected_objects):
    print("\nAnnotating objects...")

    # Ouvrir l'image et préparer le dessin
    image = Image.open(image_filename)
    fig = plt.figure(figsize=(image.width/100, image.height/100))
    plt.axis('off')
    draw = ImageDraw.Draw(image)
    color = 'cyan'

    # Dessiner chaque objet détecté
    for detected_object in detected_objects:
        r = detected_object.bounding_box
        bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height)) 
        draw.rectangle(bounding_box, outline=color, width=3)
        plt.annotate(detected_object.tags[0].name,(r.x, r.y), backgroundcolor=color)

    # Sauvegarder l'image annotée
    plt.imshow(image)
    plt.tight_layout(pad=0)
    objectfile = 'objects.jpg'
    fig.savefig(objectfile)
    print('  Results saved in', objectfile)


# ================================
# Fonction pour annoter les personnes sur l'image
# ================================
def show_people(image_filename, detected_people):
    print("\nAnnotating people...")

    # Ouvrir l'image et préparer le dessin
    image = Image.open(image_filename)
    fig = plt.figure(figsize=(image.width/100, image.height/100))
    plt.axis('off')
    draw = ImageDraw.Draw(image)
    color = 'cyan'

    # Dessiner chaque personne détectée avec confiance > 20%
    for detected_person in detected_people:
        if detected_person.confidence > 0.2:
            r = detected_person.bounding_box
            bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height))
            draw.rectangle(bounding_box, outline=color, width=3)

    # Sauvegarder l'image annotée
    plt.imshow(image)
    plt.tight_layout(pad=0)
    peoplefile = 'people.jpg'
    fig.savefig(peoplefile)
    print('  Results saved in', peoplefile)


# ================================
# Appel de la fonction principale si le script est exécuté directement
# ================================
if __name__ == "__main__":
    main()
